{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivors\n",
    "**Tim Kroehler, Jan 2020**\n",
    "\n",
    "# Summary\n",
    "The Titanic Survior competition is about trying to predict the whether a given passenger would survive or not, based on certain features.  We know something about the estimated 2222 passengers, more than 1500 of which died.  There are some holes in the dataset, which makes the feature preprocessing and engineering where the game is won or lost.\n",
    "\n",
    "# Features in the dataset\n",
    "- PassengerId: Unique Id of a passenger\n",
    "- Name: name and title of passenger\n",
    "- survival: Whether a passenger survived or not; 1 if survived and 0 if not.\n",
    "- pclass: Ticket class\n",
    "- sex: Sex\n",
    "- Age: Age in years\n",
    "- sibsp: # of siblings / spouses aboard the Titanic\n",
    "- parch: # of parents / children aboard the Titanic\n",
    "- ticket: Ticket number\n",
    "- fare: Passenger fare\n",
    "- cabin: Cabin number\n",
    "- embarked: Port of Embarkation\n",
    "\n",
    "# Narrative Information\n",
    "I would like to combine the dataset with some of the narrative information we can read about the disaster.  Especially the rule of \"woman and children first\" played a part in the Titanic disaster.  We could imagine heroic fathers putting their wives and children aboard the limited lifeboats and sending them off.  Some older people may have also heroically yield their seats, or been physically unable to board the lifeboats.  The crew may have escorted the first class passengers to the boats, and may have even prevented some of the lower class passengers from boarding.  The iceberg crash happened in the evening, and we would expect most people to be in their cabins, so those passengers in lower decks would have it harder to get to the lifeboats.  They had 15 minutes after the iceberg crash before the lifeboats were ordered out, and then one hour before the ship's front half would sink.  We would expect Age and Sex to play major roles, Fare and PClass a lesser role, and Deck or Cabin to play a smaller role, although the dataset has mostly missing data for these last two features.  Family attributes may play a role.  This is the \"human intuition\" part of the problem.\n",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Thayer-Sketch-of-Titanic.png/800px-Thayer-Sketch-of-Titanic.png\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "Part of this project is to do an exploratory data analysis.  Some of the features I would like to discard.  Some of the features will need their data filled in.  And we will also create some new features based on existing features.\n",
    "\n",
    "* PassengerId: Drop\n",
    "* Name: use to fill it sex and age for missing data\n",
    "* survival: Keep as Y\n",
    "* pclass: Keep \n",
    "* fare: Keep\n",
    "* sex: Keep \n",
    "* Age: Keep\n",
    "* sibsp: keep\n",
    "* parch: keep\n",
    "* ticket: drop\n",
    "* cabin: although it would be interesting to extract deck number and use it, there is too sparse of data in the set.  First class passengers had the upper decks that were closer to the lifeboats.  If we had near-complete data, it seems like Cabin/Deck would be a good predictor.  But we don't have it, so we'll have to use PClass.  Drop it.\n",
    "* embarked: correlate with deck number, why would port matter?  did the last passengers all go to one deck?  i think we will drop this.\n",
    "\n",
    "With the family values, we'll use the Wikipedia remarks that \"woman and children\" were given priority, and add a feature called \"vulnerable\" if they qualify.\n",
    "\n",
    "I wish there was a way to link the families, to see if there was a heroic father who put his wife and children on the boat.  The dataset doesn't link family members, however.  They might have the same last name, but there's alot of assumptions and text work to extrapolate.  I've read other data explorations that show its corr values are really low, and suggest if a family size was 1,2,or 3, the chances for survival were better, then dropping off in larger families.  What could this mean?  I don't know if I want to use much of the family data.\n",
    "\n",
    "Title seems like a nice feature to engineer.  By bringing it out of a text field (that's hard to classify) into an age field, which we know are important, it seems like we can fill in the missing data.\n",
    "\n",
    "I'm thinking a RandomForest will do the best.  We'll tune it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df=pd.read_csv(\"train.csv\")\n",
    "test_df=pd.read_csv(\"test.csv\")\n",
    "train_len=len(train_df)\n",
    "test_len=len(test_df)\n",
    "\n",
    "# combine train and test for feature engineering, tagging the test data with -1 in Survived (which is blank for test data)\n",
    "test_df['Survived']=-1\n",
    "df=pd.concat([train_df,test_df],sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory data analysis\n",
    "- a. Look at missing values in age, gender, fare, and deck (cabin)\n",
    "- b. Look at correlation between survivability and some factors\n",
    "- c. Look at correlations between factors (port and deck, age and fare, gender and fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore data\n",
    "explore_data=0\n",
    "if (explore_data==1):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent_1 = df.isnull().sum()/df.isnull().count()*100\n",
    "    percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "    missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (explore_data):\n",
    "    train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (explore_data):\n",
    "    train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (explore_data):\n",
    "    train_df['Died']= 1 - train_df['Survived']\n",
    "    train_df.groupby('Sex').agg('sum')[['Survived','Died']].plot(kind='bar',stacked=True)\n",
    "    # More men died than women.  Wikipedia article says \"woman and children first\" sentiment prevailed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using data in Title, let's assign our vulnerable column if the title is a certain kind. we won't impute age or sex from the title, however.\n",
    "def get_title(x):\n",
    "    return(x.split(',')[1].split('.')[0].strip())\n",
    "titles = set()\n",
    "for name in df['Name']:\n",
    "    titles.add(get_title(name))\n",
    "if (explore_data):\n",
    "    titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the title field, and then we'll clean it up\n",
    "df['Title']=df['Name'].map(lambda x:get_title(x))\n",
    "df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'the Countess'], 'Rare')\n",
    "df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# now we'll set the ages of each title to be the mean of each of the categories\n",
    "meanAges= df[['Title','Age']].groupby(['Title'],as_index = False).mean().sort_values(by='Age')\n",
    "df['Age'].fillna(-1, inplace=True)\n",
    "\n",
    "for id, meanage in meanAges.iterrows():\n",
    "    df.loc[(df['Age'] == -1) & (df['Title']==meanage['Title']), 'Age'] = meanage['Age']\n",
    "    df['Age']=df['Age'].astype(int)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this integer value for very vulnerable(2), somewhat vulnerable(1), or not vulnerable (0)\n",
    "df['Vulnerable']=0\n",
    "df.loc[(df['Age']<16) ,'Vulnerable']=1\n",
    "df.loc[(df['Age']<=9) | (df['Sex']==\"female\") ,'Vulnerable']= 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4. Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cleaning up of non-essential fields\n",
    "df['Male']=(df['Sex']==\"male\")\n",
    "df['Female']=(df['Sex']==\"female\")\n",
    "df.drop(columns=['Title','Name','Sex','Ticket','Cabin','Embarked'], axis=1, inplace=True)\n",
    "\n",
    "# now we'lls set the ages of each title to be the mean of each of the categories\n",
    "df['Fare'].fillna(-1, inplace=True)\n",
    "meanFares= df[['Pclass','Fare']].groupby(['Pclass'],as_index = False).mean().sort_values(by='Fare')\n",
    "for id, meanfare in meanFares.iterrows():\n",
    "    df.loc[(df['Fare'] == -1) & (df['Pclass']==meanfare['Pclass']), 'Fare'] = meanfare['Fare']\n",
    "df['Fare']=df['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Vulnerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.665544</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>31.785634</td>\n",
       "      <td>0.794613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.297222</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.703730</td>\n",
       "      <td>0.974630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age       SibSp       Parch        Fare  Vulnerable\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean     2.308642   29.665544    0.523008    0.381594   31.785634    0.794613\n",
       "std      0.836071   13.297222    1.102743    0.806057   49.703730    0.974630\n",
       "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
       "25%      2.000000   21.000000    0.000000    0.000000    7.000000    0.000000\n",
       "50%      3.000000   30.000000    0.000000    0.000000   14.000000    0.000000\n",
       "75%      3.000000   36.000000    1.000000    0.000000   31.000000    2.000000\n",
       "max      3.000000   80.000000    8.000000    6.000000  512.000000    2.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the removal and saving off of passengerId and Survived and splitting of the dataset\n",
    "survived=df['Survived']\n",
    "\n",
    "training = df[:train_len].copy()\n",
    "testing = df[train_len:test_len+train_len+1].copy()\n",
    "\n",
    "\n",
    "training.drop(columns=['PassengerId','Survived'],axis=1, inplace=True)\n",
    "passengerId=testing['PassengerId']\n",
    "testing.drop(columns=['PassengerId','Survived'], axis=1, inplace=True)\n",
    "if (explore_data):\n",
    "    training.head()\n",
    "training.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Vulnerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.045455</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.131579</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>13.056797</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.856783</td>\n",
       "      <td>0.974719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age       SibSp       Parch        Fare  Vulnerable\n",
       "count  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000\n",
       "mean     2.265550   30.045455    0.447368    0.392344   35.131579    0.818182\n",
       "std      0.841838   13.056797    0.896760    0.981429   55.856783    0.974719\n",
       "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
       "25%      1.000000   21.250000    0.000000    0.000000    7.000000    0.000000\n",
       "50%      3.000000   30.000000    0.000000    0.000000   14.000000    0.000000\n",
       "75%      3.000000   36.000000    1.000000    0.000000   31.000000    2.000000\n",
       "max      3.000000   76.000000    8.000000    9.000000  512.000000    2.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning=0\n",
    "if (tuning==1):\n",
    "    # tuning the hyperparameters\n",
    "    param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25, 50, 70], \"min_samples_split\" : [2, 4, 10, 12, 16, 18, 25, 35], \"n_estimators\": [100, 400, 700, 1000, 1500]}\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "    clf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "    clf.fit(training, survived[:train_len])\n",
    "    clf.best_params_    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of KFold CV (after a long wait)\n",
    "{'criterion': 'gini',\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 16,\n",
    " 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=12,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=True, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "forest = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=100,\n",
    "                             min_samples_split=16,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "forest.fit(training, survived[:train_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##5. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest.predict(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##6. Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  89.79\n"
     ]
    }
   ],
   "source": [
    "forest.score(training, survived[:train_len])\n",
    "accuracy = round(forest.score(training, survived[:train_len]) * 100, 2)\n",
    "print(\"Model Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.858 (0.033)\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "results = model_selection.cross_val_score(forest, training, survived[:train_len], cv=kfold, scoring='roc_auc')\n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##7. Submit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a CSV with results\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passengerId,\n",
    "    \"Survived\": predictions\n",
    "})\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
